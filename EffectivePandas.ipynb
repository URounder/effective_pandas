{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Series Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = {\n",
    "    'index': [0,1,2,3],\n",
    "    'data': [145,142,38,13],\n",
    "    'name': 'songs'\n",
    "}\n",
    "\n",
    "def get(series, idx):\n",
    "    value_idx = series['index'].index(idx)\n",
    "    return series['data'][value_idx]\n",
    "\n",
    "get(series,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The double abstraction is used in pandas because it allows for other\n",
    "# data types in the index\n",
    "\n",
    "songs = {\n",
    "    'index': ['Paul','John','George','Ringo'],\n",
    "    'data': [145,142,38,13],\n",
    "    'name': 'counts'\n",
    "}\n",
    "\n",
    "get(songs,'John')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a series in pandas\n",
    "import pandas as pd\n",
    "\n",
    "songs2 = pd.Series([145,142,38,13],\n",
    "            name='counts')\n",
    "songs2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Paul      145\n",
       "John      142\n",
       "George     38\n",
       "Ringo      13\n",
       "Name: counts, dtype: Int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "songs3 = pd.Series([145,142,38,13],\n",
    "            name='counts',\n",
    "            index=['Paul','John','George','Ringo'],\n",
    "            )\n",
    "\n",
    "# .count() method returns the non-null values in a series\n",
    "print(songs3.count())\n",
    "\n",
    "# inspecting the .size property gives you the number of entries\n",
    "print(songs3.size)\n",
    "\n",
    "# 'Int64' is a datatype in pandas that allows Null types as an alternative to\n",
    "# letting pandas convert int64 to a float (which uses more memory).\n",
    "songs3.astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Similar to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "142\n",
      "84.5\n",
      "84.5\n"
     ]
    }
   ],
   "source": [
    "# The Series object behaves similarly to a NumPy array. Both respond to \n",
    "# the index operations.\n",
    "numpy_ser = np.array([145,142,38,13])\n",
    "print(songs2[1])\n",
    "print(numpy_ser[1])\n",
    "\n",
    "# They both have methods in common:\n",
    "print(songs2.mean())\n",
    "print(numpy_ser.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They also both have a notion of a boolean array. A boolean array is a series with the same index as the series you are working with that has boolean values, and it can be used as a mask to filter out items. Normal Python lists do not support such fancy index operations, like sticking a list into an index operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paul       True\n",
       "John       True\n",
       "George    False\n",
       "Ringo     False\n",
       "Name: counts, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a 'mask' using pandas series (what is a mask?)\n",
    "mask = songs3 > songs3.median() # boolean array\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a mask, we can use that as a filter. We just need to pass the mask into an index operation. If the mask has a 'True' value for a given index, the value is kept. Otherwise, the value is dropped. The mask above represents the locations that have a value higher than the medion value af the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paul    145\n",
       "John    142\n",
       "Name: counts, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs3[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([145, 142])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy can also filter by boolean arrays, but lacks the .median method on an array.\n",
    "# Instead NumPy provides a median function in the NumPy namespace.\n",
    "# The equivalent version in NumPy:\n",
    "\n",
    "numpy_ser[numpy_ser > np.median(numpy_ser)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Categorical Data\n",
    "You can load data as categorical if you know it is limited to only a few values.\n",
    "##### Benefits:\n",
    "- Use less memory than strings\n",
    "- Improve performance\n",
    "- Can have an ordering\n",
    "- Can perform operations or categories\n",
    "- Enforce membership on values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     m\n",
       "1     l\n",
       "2    xs\n",
       "3     s\n",
       "4    xl\n",
       "dtype: category\n",
       "Categories (5, object): ['l', 'm', 's', 'xl', 'xs']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create category:\n",
    "s = pd.Series(['m','l','xs','s','xl'], dtype='category')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default categories do not have an ordering:\n",
    "# The cat attribute has various properties\n",
    "s.cat.ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      m\n",
       "1      l\n",
       "2    NaN\n",
       "3      s\n",
       "4    NaN\n",
       "dtype: category\n",
       "Categories (3, object): ['s' < 'm' < 'l']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To canvert a non-categorical series to an ordered category, we can create a type\n",
    "# with the 'CategoricalDtype' constructor and the appropriate parameters.\n",
    "# Then we pass this type into the .astype method:\n",
    "\n",
    "s2 = pd.Series(['m','l','xs','s','xl'])\n",
    "size_type = pd.api.types.CategoricalDtype(\n",
    "    categories=['s','m','l'], ordered=True)\n",
    "s3 = s2.astype(size_type)\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The categoris not in the CategoricalDtype were replaced with NaN.\n",
    "# Perform comparisonns on the ordered categories now:\n",
    "s3 > 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     m\n",
       "1     l\n",
       "2    xs\n",
       "3     s\n",
       "4    xl\n",
       "dtype: category\n",
       "Categories (5, object): ['xs' < 's' < 'm' < 'l' < 'xl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can add ordering information to existing categorical data:\n",
    "# You have to include all categories or pandas will throuw a ValueError\n",
    "\n",
    "s.cat.reorder_categories(['xs','s','m','l','xl'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      L\n",
       "2    NaN\n",
       "3      S\n",
       "4    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# String and datetime series have a str and dt attribute that allow us to perform \n",
    "# commen operations specific to thet type. If we convert these types to\n",
    "# categorical types, we can still use the str or dt attributes[method?] on them:\n",
    "s3.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Introduction\n",
    "pd.series(data=None, index=None, dtype=None, name=None) <br>\n",
    "Create a series from data (sequeence, dictionary, or scalar) <br>\n",
    "<br>\n",
    "s.index <br>\n",
    "Access index of series <br>\n",
    "<br>\n",
    "s.astype(dtype, errors='raise') <br>\n",
    "Cast a series to dtype. To ignore errors (and return original object) use errors='ignore' <br>\n",
    "<br>\n",
    "s[boolean_array] <br>\n",
    "Return values from s where boolean_array is True <br>\n",
    "<br>\n",
    "s.cat.ordered <br>\n",
    "Determine if a categorical series is ordered <br>\n",
    "<br>\n",
    "s.cat.reorder_categories(new_categories, ordered=False) <br>\n",
    "Add categories (potentially ordered) to the series. new_categories must include all categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "1. Create a series with temperature values for the last seven days. Filter out values below the mean.\n",
    "2. Create a series with colors. Use categorical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    78\n",
       "2    66\n",
       "3    67\n",
       "Name: temperature, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures = pd.Series(data=[78,63,66,67,65,61,56], name='temperature')\n",
    "mean_temp = temperatures > temperatures.mean()\n",
    "temperatures[mean_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Blue\n",
       "1     Green\n",
       "2       Red\n",
       "3    Orange\n",
       "Name: colors, dtype: category\n",
       "Categories (4, object): ['Blue', 'Green', 'Orange', 'Red']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "colors = pd.Series(data=['Blue','Green','Red','Orange'], \n",
    "                    dtype='category', \n",
    "                    name='colors')\n",
    "\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Series Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Loading the Data\n",
    "US Fuel Economy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EricGraul\\AppData\\Local\\Temp\\ipykernel_45392\\1465846490.py:3: DtypeWarning: Columns (68,70,71,72,73,74,76,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://github.com/mattharrison/datasets/raw/master/data/vehicles.csv.zip'\n",
    "df = pd.read_csv(url)\n",
    "city_mpg = df.city08\n",
    "highway_mpg = df.highway08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         9\n",
       "2        23\n",
       "3        10\n",
       "4        17\n",
       "         ..\n",
       "41139    19\n",
       "41140    20\n",
       "41141    18\n",
       "41142    18\n",
       "41143    16\n",
       "Name: city08, Length: 41144, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        25\n",
       "1        14\n",
       "2        33\n",
       "3        12\n",
       "4        23\n",
       "         ..\n",
       "41139    26\n",
       "41140    28\n",
       "41141    24\n",
       "41142    24\n",
       "41143    21\n",
       "Name: highway08, Length: 41144, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dir function in pandas will list all the attributes available on an object.\n",
    "\n",
    "len(dir(city_mpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series Attributes\n",
    "- Dunder methods (.__add__, .__itr__, etc.) provide many numeric operations, looping, attribute access, and index access. For the numeric operations, these return a series.\n",
    "- Corresponding operator methods for many of the numeric operations allow us to tweak the behavior(there is a .add method in addition to .__add__)\n",
    "- Aggregate methods and properties which reduce or aggregate the values in a series down to a single scalar value. The .mean., .max, and .sum methods and .is_monotonic property are all examples.\n",
    "- Conversion methods. Some of these start with .to_ and export the data to other formats.\n",
    "- Manipulation methods such as .sort_values, .drop_duplicates, that return Series objects with the same index.\n",
    "- Indexing and accessor methods and attributes such as .loc and .iloc. These return Series or scalars.\n",
    "- String manipulation methods using .str.\n",
    "- Date manipulation methods using .dt.\n",
    "- Plotting methods using .plot.\n",
    "- Categorical manipulation methods using .cat.\n",
    "- Transformation methods such as .unstack and .reset_index, .agg, .transform.\n",
    "- Attributes such as .index and .dtype.\n",
    "- A bunch of private attributes that we will ignore (around 130 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "# How many attributes are faund on the .str attribute\n",
    "ds = pd.Series(data=['hello','goodbye'])\n",
    "ds2 = pd.Series(pd.date_range('2000-01-01',periods=3,freq='s'))\n",
    "print(len(dir(ds.str)))\n",
    "print(len(dir(ds2.dt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Operators & Dunder Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Dunder Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Under the covers\n",
    "(2).__add__(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        22.0\n",
       "1        11.5\n",
       "2        28.0\n",
       "3        11.0\n",
       "4        20.0\n",
       "         ... \n",
       "41139    22.5\n",
       "41140    24.0\n",
       "41141    21.0\n",
       "41142    21.0\n",
       "41143    18.5\n",
       "Length: 41144, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Python integer object that has a .__add__ method respond to the + operation.\n",
    "# Because a Series object has this method, you can call + on it. There is also\n",
    "# a .__div__ method that supports division. \n",
    "# \n",
    "# One way to calculate the average of the average of the two series:\n",
    "\n",
    "(city_mpg + highway_mpg) / 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Index Alignment\n",
    "\n",
    "When you operate with two series pandas will align the index before performing the operation. Aligning will take tach index entry in the left series and match it up with EVERY entry with the same index of the right series. Because of this the indexes should be:\n",
    "- unique (no duplicates)\n",
    "- common to both series<br>\n",
    "\n",
    "Either of these will cause create nan values or a combinatoric explosion respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     NaN\n",
       "2    55.0\n",
       "2    64.0\n",
       "2    65.0\n",
       "2    74.0\n",
       "4     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([10,20,30],index=[1,2,2])\n",
    "s2 = pd.Series([35,44,53],index=[2,2,4])\n",
    "s1 + s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Broadcasting\n",
    "__What is scalar and example:__<br>\n",
    "Scalar, a physical quantity that is completely described by its magnitude. Examples of scalars are volume, density, speed, energy, mass, and time. Other quantities, such as force and velocity, have both magnitude and direction and are called vectors.<br>\n",
    "\n",
    "When you perform math operations with a scalar, pandas broadcasts the operation to all values. In the above case, the values are added together. This makes it easy to write mathematical operations. It also makes the code easy to read.<br>\n",
    "\n",
    "With many math operations, these are optimized and happen quickly in the CPU. This is called vectorization. CPUs leverage a technorogy called Single Instruction/Multiple Data (SIMD) to apply math operations to a block of memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Iteration\n",
    "There is an .__iter__ method but it should usually not be used. This does not use vectorization and C and so you loose important benefits of pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Operator Methods\n",
    "Why are there methods and operators?<br>\n",
    "In general, functions and methods have parameters to allow you to parameterize or change the behavior based on the parameters. The dunder methods generally fill in NaN when one of the operands is missing following index alignment. The operator methods have a fill_value parameter that changes this behavior. If one of the operands is missing, it will use the fill_value instead.<br>\n",
    "\n",
    "If we call the .add method with the default parameters, we will have the same result as the + operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     NaN\n",
       "2    55.0\n",
       "2    64.0\n",
       "2    65.0\n",
       "2    74.0\n",
       "4     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     NaN\n",
       "2    55.0\n",
       "2    64.0\n",
       "2    65.0\n",
       "2    74.0\n",
       "4     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.add(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10.0\n",
       "2    55.0\n",
       "2    64.0\n",
       "2    65.0\n",
       "2    74.0\n",
       "4    53.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# However, we can use the fill_value paramater to specify that we use zero instead:\n",
    "\n",
    "s1.add(s2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Chaining\n",
    "Another stylistic reason to prefer the method to the operator is that it makes chaining manipulations easier. Because most pandas methods do note mutate data in place but instead return a new object. We will see many examples of this. Chaining makes the code easy to read and understand. We can chain with operators as well, but it requires that we wrap the operation with parentheses.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        22.0\n",
       "1        11.5\n",
       "2        28.0\n",
       "3        11.0\n",
       "4        20.0\n",
       "         ... \n",
       "41139    22.5\n",
       "41140    24.0\n",
       "41141    21.0\n",
       "41142    21.0\n",
       "41143    18.5\n",
       "Length: 41144, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below we calculate the average of city and highway mileage using operators:\n",
    "\n",
    "(city_mpg + highway_mpg)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        22.0\n",
       "1        11.5\n",
       "2        28.0\n",
       "3        11.0\n",
       "4        20.0\n",
       "         ... \n",
       "41139    22.5\n",
       "41140    24.0\n",
       "41141    21.0\n",
       "41142    21.0\n",
       "41143    18.5\n",
       "Length: 41144, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of chaining to calculate the average:\n",
    "\n",
    "(city_mpg\n",
    "    .add(highway_mpg)\n",
    "    .div(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, but chaining can lead to understanding your code. I like to put these operations in their own line. I read this as <br>\n",
    "\"we are taking the city_mpg series, then we are adding the highway_mpg series to it. Finally we are dividing by two.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 - Aggregate Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate methods collapse the values of a series down to a scalar. Aggregations are the numbers that your boss wants to be reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Aggregations\n",
    "\n",
    "calulate mean by using an aggregation method, .mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.369045304297103"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a few aggregate properties. Thes start with .is_ \n",
    "you don't call them, they evaluate to true or false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.quantile(.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1    13.0\n",
       "0.5    17.0\n",
       "0.9    24.0\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.quantile([.1,.5,.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Cont and Mean of an Attribute\n",
    "Neat trick, if you want the count of values that meet some criteria, you can use the .sum method. <br>\n",
    "For example to get cout and % of cars with milege greater than 20, we can use:<br>\n",
    "\n",
    "DataFrame.gt(other, axis='columns', level=None)[source]<br>\n",
    "Get Greater than of dataframe and other, element-wise (binary operator gt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10272"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.gt(20).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.965973167412017"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want the % of values that meet some criteria you can apply the .mean method\n",
    "city_mpg.gt(20).mul(100).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trick comes from the fact that Python treats True as 1 and False as 0.<br>\n",
    "If you sum up a series of boolean values, the result is the count of True values.<br>\n",
    "If you take the mean of a series of boolean values, the result is the fraction of values that are true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 .agg and Aggregation Strings\n",
    "Finall, the .agg method takes in a string and transforms the data depending on how it was called.<br>\n",
    "It shines in the ability to perform multiple aggregations at once.<br>\n",
    "NumPy reduction functions, Python aggregations, or define your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean               18.369045\n",
       "var                62.503036\n",
       "max               150.000000\n",
       "second_to_last     18.000000\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def second_to_last(s):\n",
    "    return s.iloc[-2]\n",
    "\n",
    "city_mpg.agg(['mean',np.var,max,second_to_last])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 - Conversion Methods\n",
    "Sometimes you will need to change the type of data. This may be do to formats that do not include type information, or it may be that you can have better performance by changing types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 - Automatic Conversion\n",
    ".convert_dtypes > This tries to convert a Series to a type that supports pd.NA.<br>\n",
    "In the city_mpg it will change the type from int64 to Int64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         9\n",
       "2        23\n",
       "3        10\n",
       "4        17\n",
       "         ..\n",
       "41139    19\n",
       "41140    20\n",
       "41141    18\n",
       "41142    18\n",
       "41143    16\n",
       "Name: city08, Length: 41144, dtype: Int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
